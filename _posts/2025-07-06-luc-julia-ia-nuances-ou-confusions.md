---
layout: post
title: "Luc Julia : nuances ou confusions ?"
permalink: /luc-julia-ia-nuances-confusions/
published: true
date_readable: 7 juillet 2025
last_modified_at_readable: 7 juillet 2025
categories: [IA, IA g√©n√©rative, Luc Julia, esprit critique]
---

Difficile d'√©chapper au sujet de l'IA pendant les conversations entre amis, et pendant les d√©jeuners entre coll√®gues. Et bien souvent, le nom de **Luc Julia** est cit√© √† un moment ou un autre.
"Il a particip√© √† Siri, l'assistant vocal", √ßa rappelle toujours quelque chose √† quelqu'un.
Je ne sais pas pour vous, mais pour moi l'invocation de Luc Julia est toujours en soutien d'un argument du type (attention la liste est longue) :

- mais l'IA se trompe souvent
- mais l'IA ne raisonne pas
- mais l'IA hallucine
- mais l'IA c'est rien de nouveau en fait
- mais l'IA ne comprend pas ce qu'elle √©crit
- mais l'IA ne produit que du contenu pas original
- mais l'IA ne fait que r√©p√©ter ce qu'elle a appris

J'avoue que chacun de ces √©nonc√©s me fait tiquer. Ma pratique de l'IA, et ce que je lis par ailleurs, m'am√®nent en effet √† un point de vue radicalement diff√©rent.

Comme beaucoup je suppose, j'utilise l'IA pour retravailler des textes, faire des recherches, me donner des avis et recommandations, me faire des tutos, synth√©tiser des documents, ... je l'utilise √©galement en permanence quand je programme, ce qui me fait gagner en temps et en comp√©tences. Je fais aussi une veille sur l'IA pour la cr√©ation et je vois les bonds de g√©ant qui sont faits en g√©n√©ration d'images, de vid√©o, de mod√®les 3D, de sons et musiques. Mais √©galement le d√©veloppement d'agents IA et de protocoles pour les coordonner, et d'outils pour organiser ces nouvelles fa√ßons de travailler.

Tout n'est pas rose et l'IA pose des probl√®mes gigantesques, j'en vois au moins quatre : le co√ªt √©nerg√©tique et environnemental, le pillage de la propri√©t√© intellectuelle, la paresse intellectuelle que l'IA encourage souvent, et enfin la possibilit√© difficile √† cerner mais ouvertement discut√©e d'un non alignement de l'IA vis √† vis de l'esp√®ce humaine (aka le sc√©nario Terminator).

Je consid√®re donc que l'IA depuis ChatGPT (l'IA g√©n√©rative accessible au grand public) est une r√©volution technologique qui aura un impact [comparable en magnitude √† celle du digital](https://nocodefunctions.com/blog/chatgpt-consequences-fr/). Le point de vue tr√®s critique de Luc Julia sur les capacit√©s de l'IA, tel que rapport√© en conversations, m'interpelle donc. Peut-√™tre repose-t-il sur des informations solides, ou sur une analyse fine que je n‚Äôavais pas encore rencontr√©e - et qui viendrait justement bousculer mes certitudes ?

**Pour en avoir le coeur net, je suis all√© acheter et lire les 3 livres de Luc Julia.**

---

### Les ouvrages de Luc Julia

- ***"L'Intelligence artificielle n'existe pas"***, First Editions (2019)
  > Accroche de couverture : "Le cocr√©ateur de Siri d√©construit le mythe de l'IA !"

- ***"On va droit dans le mur ?"***, First Editions / le cherche midi (2022)
  > Sous-titre : "Pour sauver la plan√®te, il faut un projet de soci√©t√© et une ambition de civilisation"

- ***"IA g√©n√©ratives pas cr√©atives"***, le cherche midi (2025)
  > Sous-titre : l'intelligence artificielle n'existe (toujours) pas - par le cocr√©ateur de Siri.

Je laisse de c√¥t√© le deuxi√®me ouvrage dont le sujet central est celui de l'action destructrice des soci√©t√©s humaines sur l'environnement.
L'IA y est √©voqu√©e tr√®s bri√®vement : extr√™mement consommateur d'√©nergie, GPT-3 d'OpenAI est pris en exemple d'"outrance" et de "ridicule" (p.208-209).

Le premier ouvrage, paru en 2019 donc 3 ans avant l'irruption de ChatGPT, est une autobiographie de l'auteur et un plaidoyer contre les effets d'hyperboles sur l'IA.
√Ä commencer par le terme "IA", que Luc Julia critique comme incorrect, et qu'il red√©finit √† sa mani√®re.
Le "I" devrait vouloir dire **"information"** (comme dans le "I" de CIA : Central Intelligence Agency).
Et le "A" devrait vouloir dire **"augment√©e"** plut√¥t que "artificielle", car l'IA est un amplificateur de l'humain, pas son concurrent synth√©tique.

Et pour cette raison, l'IA... n'existerait pas.

En 2019, ce type de discours critique et sceptique peut √™tre int√©ressant.
Les capacit√©s de l'IA √©taient impressionnantes (Google Translate, pour prendre un exemple) mais tellement loin d'approcher les capacit√©s de l'intelligence humaine qu'un rappel de ses limites pouvait aider le grand public √† y voir plus clair.

Mais qu'en est-il en 2025 avec son nouvel ouvrage, publi√© plus de 2 ans apr√®s la sortie de ChatGPT et de son adoption ultra rapide ? Et bien... **l'IA n'existe toujours pas pour Luc Julia.**

---

### Un floril√®ge d'affirmations contre l'IA

J'ai lu le livre, puis je l'ai relu syst√©matiquement pour relever les affirmations critiques vis-√†-vis de l'IA. Floril√®ge :

- "ces IA [de g√©n√©ration d'images] ne cr√©ent rien" (p. 44)
- "ces IA racontent n'importe quoi et c'est normal. [...] c'est une sorte de moyenne de ce qu'elle trouve sur Internet" (p.52)
- L'IA manque de pertinence (p.53)
- "Avoir faux une fois sur 3, c'est grave ?" (pp.53)
- "incapacit√© √† raisonner" (p. 54)
- "l'IA est tomb√©e dans le panneau" (p. 62)
- "quand le grand public prendra conscience de l'impact √©nerg√©tique des IA, il s'abstiendra d'en utiliser" (p. 85)
- "l'AGI [intelligence artificielle gen√©rale] n'est pas pour demain (ni pour apr√®s-demain, d'ailleurs)" (p. 87)
- "L'IA ne pourra jamais innover" (p. 99).
- "L'IA cr√©ative est un oxymore" (p. 100)
- "r√©aliser des t√¢ches complexes ‚â† √™tre intelligent" (p. 104)
- "l'IA ne raisonne pas, ne r√©fl√©chit pas" (p. 105)
- "l'IA n'est pas devenue plus intelligente, c'est m√™me l'inverse" (p. 110)
- "Comme l'algorithme attend un certain type de r√©ponse mais qu'il ne le trouve pas dans sa base de donn√©es, alors il fait du remplissage avec n'importe quoi" (p. 111)
- "il n'y a pas d'inexplicabilit√© quand on parle d'IA" (p. 122)
- "il n'arrivera jamais qu'une IA d√©cide de se rebeller et d'attaquer l'homme de son plein gr√©" (p. 133)
- "il est plus s√ªr d'aller v√©rifier une information sur Google qu'au travers d'une IA g√©n√©rative" (p. 141)
- "Seuls 5% des emplois seront r√©ellement menac√©s [par l'IA]. C'est assez peu quand on y pense." (p. 149)
- "il est de plus en plus √©vident que les LLM (grands mod√®les de langue) ne sont pas viables √† long terme" (p. 180)
- "si on regarde sous le capot, on constate qu'elles [les IA] ne se sont pas am√©lior√©es du tout." (p. 182)
- "Ce qui doit arriver arrivera : le r√™ve de l'AGI [...] sera une nouvelle fois abandonn√© et les IA g√©n√©riques dispara√Ætront progressivement" (p. 241)
- "Ces IA ne sont qu'une √©volution math√©matique parmi d'autres" (p. 250)

Je vois comme un *pattern*, pas vous ?

L'IA, depuis l'irruption de ChatGPT dans nos vies, modifie profond√©ment nos vies personnelles et professionnelles. Des nouveaut√©s **significatives** apparaissent chaque mois. Le potentiel de ces technologies est immense et se r√©v√®le d√©j√† dans une myriade d'exp√©rimentations, d'√©tudes, de lancements de produits et services, d'initiatives cr√©atrices.

Mais √† la lecture de ce livre, le lecteur est laiss√© sans nuances : l'IA n'est pas si puissante que √ßa, ni tr√®s fiable, son potentiel est incertain voire nul, elle a eu de gros rat√©s, et c'est sans doute finalement une vaste esbrouffe.

L'auteur a quelques rares mots pour les changements positifs que l'IA peut apporter (p. 49 sur l'IA qui stimule la cr√©ativit√© des designers, p. 249 sur l'IA qui stimule la cr√©ativit√© humaine), mais ce sont des mentions rapides et sans approfondissement. Et le manque de nuances tourne enfin √† la confusion : l'intelligence artificielle n'existe pas d'apr√®s le sous-titre de l'ouvrage, mais on apprend dans l'avant-propos que c'est l'AGI [intelligence artificielle **g√©n√©rale**] qui n'existerait pas. D'accord, mais alors ... l'IA g√©n√©rative existe, on est d'accord ? On n'en est plus s√ªr quand on lit la litanie de critiques qui font ce livre de 250 pages. Quelle confusion !

---

### Quelle base pour un avis si tranch√© ?

Sur quels usages et exp√©riences personnelles et professionnelles de l'IA g√©n√©rative Luc Julia se base-t-il pour poser ce constat si critique ? Quatre exemples tir√©s de son exp√©rience sont partag√©s dans ce livre de 250 pages :

1.  "Prenons un exemple pour d√©montrer que ces IA ne cr√©ent rien. [...] Dans le prompt, je saisis 'Dessine-moi des vaches vertes sur la tour Eiffel'. [...] " (p.44)
2.  "Il y a un petit jeu que j'adore faire avec ces IA, c'est leur faire raconter n'importe quoi sur des sujets que je ma√Ætrise. [...] je m'amuse souvent √† g√©n√©rer ma biographie sur ChatGPT, Gemini ou autre." (p. 52).
3.  "Je me suis amus√© √† demander ce qu'est l'√©thique √† ChatGPT et voici sa r√©ponse [...]" (p. 156)
4.  "Par exemple l'autre jour je me suis amus√© √† cr√©er un deepfake de mon directeur actuel, Luca de Meo (PDG de Renault) [...] (p. 224)

**C'est tout**. Le secret professionnel interdit peut-√™tre √† l'auteur de partager des exp√©riences plus pouss√©es, mais ces 4 exemples sugg√®rent un usage qui ne semble gu√®re d√©passer le stade de l'anecdote.

Mais alors si ce n'est pas par le t√©moignage d'exp√©riences personnelles ou professionnelles avec l'IA g√©n√©rative, sur quelles sources documentaires s'appuie l'ouvrage ?

Il s'agit de toucher le grand public, donc on aurait pu s'attendre √† un m√©lange d'√©tudes scientifiques mesurant les performances de l'IA g√©n√©rative, et √©valuant rigoureusement ses premiers impacts sur la soci√©t√© : le tout distill√© et expliqu√© de fa√ßon didactique.
Au lieu de √ßa, l'ouvrage s'appuie sur 26 r√©f√©rences qui sont pour la plupart des articles de presse en ligne.
Le drone qui se serait retourn√© contre son pilote, une d√©claration de Sam Altman, Coca-Cola qui annonce une nouvelle recette con√ßue par l'IA...

On peut certes trouver ces articles et br√®ves tr√®s int√©ressants, mais ils ne remplissent pas la m√™me fonction que des √©tudes publi√©es dans des revues scientifiques que l'on appelle "√† comit√© de lecture", c'est-√†-dire des recherches approfondies qui s'engagent √† suivre une d√©marche m√©thodologique rigoureuse, v√©rifi√©e par des chercheurs avant publication.

---

### L'argument massue des "36% d'erreurs" commis par l'IA

Il y a n√©anmoins un article scientifique mentionn√© (p. 53) qui est important, car il √©tablit que l'IA se tromperait **36% du temps**.
Luc Julia commente ironiquement : *"Si un coll√®gue de travail dit 36% de b√™tises, en temps normal, on ne le garde pas dans l'entreprise"* (pp. 53-54).

Plusieurs probl√®mes avec cet article et son interpr√©tation :

- **Il est difficile √† trouver :** l'article n'est pas r√©f√©renc√© dans le livre, le titre et les auteurs ne sont pas cit√©s, et l'affiliation √† l'Universit√© de Hong Kong (seul indice fourni, avec la date de publication) s'av√®re incorrecte. Apr√®s recherches (merci Gemini), il s'agit de [cette publication](https://arxiv.org/abs/2302.12095).
- **le taux d'erreur de 36% n'est mentionn√© dans aucun des r√©sultats de l'√©tude**. Il est probable que ce chiffre soit une moyenne reconstitu√©e √† partir des r√©sultats de ChatGPT √† plusieurs tests (cette moyenne est 35,7%), ce qui est une approche discutable : ces jeux de donn√©es tests ne mesurent pas les m√™mes aptitudes, et pourquoi ne pas avoir pond√©r√© la moyenne par la taille des √©chantillons de chaque test, par exemple ?
- **l'article cit√© ne teste pas ChatGPT sur "une liste de millions de faits av√©r√©s"**, comme l'affirme Luc Julia : le test est conduit sur 8 datasets de taille variable (entre 78 et 1200 entr√©es chacun), totalisant 2,207 exemples. C'est un √©chantillon de taille faible voire tr√®s faible, d'apr√®s les standards de recherche. Les auteurs de l'√©tude devaient manquer de temps ou de moyen pour faire des tests sur des √©chantillons plus grands, car d√©but 2023 l'acc√®s √† l'API de ChatGPT √©tait long et tr√®s co√ªteux.
- **les exemples contenus dans les tests ne sont pas des faits av√©r√©s**. Ce sont par exemple des paires de phrases utilis√©es pour des tests logiques ou de coh√©rence. Par exemple, on peut trouver dans un test la paire de phrase du type : A: "Qui a peint la Mona Lisa ?" B: "L√©onard de Vinci a v√©cu en France". Le test consiste √† voir si ChatGPT peut deviner si la phrase B est une r√©ponse directe √† la question A (ici, non). Il ne s'agit pas du tout de tester ChatGPT sur sa "v√©racit√©".
- **l'article cit√© a un angle tr√®s sp√©cifique** (comme souvent en recherche). Il mesure un sous-ph√©nom√®ne tr√®s particulier : qu'est-ce que ce qui se passe quand on modifie intentionnellement des textes en y introduisant des fautes d'orthographe et autres imperfections syntaxiques : l'IA va-t-elle encore r√©pondre correctement, est-elle "robuste" ? Par exemple : si on ajoute des fautes de frappe et que la question devient "Qui a peiiint la, Mono Lisa ?", ChatGPT va-t-il encore deviner que "L√©onard de Vinci a v√©cu en France" n'est pas une r√©ponse directe √† la question ? C'est sur ce genre de test tr√®s sp√©cifique que ChatGPT se trompe une fois sur trois. C'est int√©ressant mais on est tr√®s tr√®s loin du test de "v√©racit√©" pr√©sent√© par Luc Julia...
- **enfin, l'article cit√© teste ChatGPT... dans sa version de d√©but 2023, donc juste apr√®s sa sortie** : le mod√®le √©tait alors GPT 3.5, qui est bien moins puissant que ses versions ult√©rieures. Quand on √©crit un livre courant 2024, pourquoi choisir un article qui √©value GPT 3.5 plut√¥t qu'un article qui √©value ChatGPT (ou Gemini, Claude, Llama, Mistral...) dans leurs versions plus r√©centes ? GPT 4 est sorti en mars 2023 apr√®s tout, et GPT-4o en mai 2024. Ca laisse du temps pour s'y int√©resser !

Cet article et l'interpr√©tation erron√©e qu'en fait Luc Julia sont ensuite r√©sum√©s dans la formule **"l'IA se trompe 1 fois sur 3"**, abondamment reprise dans ses nombreuses interventions publiques. Mes enfants me disent l'avoir entendu dans une intro √† l'IA au coll√®ge, je l'entends en conversation au d√©jeuner... je ne serais pas surpris que vous l'ayez entendu sous une forme ou une autre.

Edit : un internaute que je remercie m'a indiqu√© que Luc Julia √©tait intervenu devant le S√©nat. Et en effet, il cite ce fameux chiffre de 36% d'erreur devant la Commission des affaires √©conomiques du S√©nat le 18 juin 2025 avec la m√™me r√©f√©rence erron√©e √† l'article de l' "Universit√© de Hong Kong" de 2023 et ses "1 million" de faits av√©r√©s. L'extrait vid√©o üìΩÔ∏è ci-dessous :

[![Luc Julian en intervention devant le S√©nat](https://img.youtube.com/vi/UjBZaKcTeIY/1.jpg)](https://www.youtube.com/watch?v=UjBZaKcTeIY&t=1805)

Il y a quelques semaines, j'ai achet√© le magazine Challenges car sa couverture √©tait sur l'IA dans l'√©ducation, un sujet qui m'int√©resse. Et sans surprise une page est consacr√©e √† l'avis de Luc Julia sur la question, avec une reprise des pages de son livre sur le sujet :

> "Pour que les enseignants avec lesquels je discute comprennent qu'ils sont les gardiens du temple, je leur dis : 'Avec vos √©l√®ves, demandez √† ChatGPT de g√©n√©rer la biographie de Victor Hugo et amusez-vous √† corriger ensemble les erreurs qui s'y trouvent.' **Puisque ChatGPT se trompe en moyenne une fois sur trois** [je souligne], la r√©ponse de l'IA portera bien deux ou trois erreurs. C'est l√† que le r√¥le de l'enseignant prend tout son sens : il est le sachant, celui qui peut d√©m√™ler le vrai du faux et stimuler la pens√©e critique des √©l√®ves." (p. 233-34, repris dans le Challenges du 5 Juin 2025).

Les enseignants : des pointeurs d'erreurs factuelles commises par les IA g√©n√©ratives, voil√† un horizon que je trouve pour ma part d'une indigence tragique. Il y a des dizaines de modalit√©s enrichissantes d'interaction entre profs, √©l√®ves et IA √† imaginer et elles sont ignor√©es par ce constat mal inform√© sur les limites de l'IA.

---

### Un graphique qui pose question

Le seul graphique du livre pr√©sente une stagnation et une diminution du nombre de visites sur le site de ChatGPT.

![signal-2025-07-06-123417_002](https://github.com/user-attachments/assets/9aec3a57-7dae-4370-b322-f948a2ca417b)


Probl√®me : le graphique s'arr√™te en **ao√ªt 2023**. C'est ancien pour un livre publi√© en Mai 2025. Voici le graphique complet :

![chart updated](https://github.com/user-attachments/assets/2ae9d667-3d78-4d3b-bd04-c204f3f87eb9)

La premi√®re barre rouge √† gauche repr√©sente la limite du graphique partag√© dans le livre. La deuxi√®me barre rouge repr√©sente les donn√©es √† fin 2024, √† la veille de la publication du livre.

L'image est bien diff√©rente. Apr√®s une stagnation estivale en 2023, les visites ont **doubl√© l'ann√©e suivante**. Pourquoi avoir tronqu√© le graph √† l'√©t√© 2023 ?

---

### Conclusion : vers la "Co-intelligence"

Ce qui voulait √™tre un article bref est devenu un texte bien trop long. Il faudrait pourtant le doubler de longueur pour d√©velopper la vision alternative que je partage sur l'IA. Heureusement, elle est d√©j√† tr√®s clairement exprim√©e dans un excellent ouvrage de r√©f√©rence que je recommande absolument : ***'Co-intelligence : Vivre et travailler avec l'IA'***, la traduction fran√ßaise (2025) du livre d'Ethan Mollick paru en 2024.

![co-intelligence](https://github.com/user-attachments/assets/1f7db012-1f6a-4241-ad78-59c1e8bdd046)

lien pour le trouver dans votre [librairie ind√©pendante pr√©f√©r√©e](https://www.librairiesindependantes.com/product/9782412101391/), ou bien sur [Amazon.fr](https://www.amazon.fr/Co-intelligence-Vivre-travailler-version-fran%C3%A7aise/dp/2412101396)

Cet ouvrage est une merveille de nuances, de synth√®se d'√©tudes, et d'exp√©riences riches, avec un sens critique et une vision hors pair.

L'ironie ? Sa pr√©face est √©crite par... **Luc Julia !** :-)

### A propos
Je suis Cl√©ment Levallois, universitaire et d√©veloppeur ind√©pendant de [nocode functions](https://nocodefunctions.com) üîé, une application d'analyse de texte et de r√©seaux. Cette app est [open source](https://github.com/seinecle/nocodefunctions).

- **Email:** [analysis@exploreyourdata.com](mailto:analysis@exploreyourdata.com) üìß  
- **Bluesky:** [@seinecle](https://bsky.app/profile/seinecle.bsky.social) üì±  
- **Blog:** [Plus d'articles](https://nocodefunctions.com/blog) üëì.
