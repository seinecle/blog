---
layout: post
title: "Luc Julia : nuances ou confusions ?"
permalink: /luc-julia-ia-nuances-confusions/
published: false
date_readable: 7 juillet 2025
last_modified_at_readable: 7 juillet 2025
categories: [IA, IA générative, Luc Julia, esprit critique]
---

Difficile d'échapper au sujet de l'IA pendant les conversations entre amis, et pendant les déjeuners entre collègues. Et bien souvent, le nom de **Luc Julia** est cité à un moment ou un autre.
"Il a participé à Siri, l'assistant vocal", ça rappelle toujours quelque chose à quelqu'un.
Je ne sais pas pour vous, mais pour moi l'invocation de Luc Julia est toujours en soutien d'un argument du type (attention la liste est longue) :

- mais l'IA se trompe souvent
- mais l'IA ne raisonne pas
- mais l'IA hallucine
- mais l'IA c'est rien de nouveau en fait
- mais l'IA ne comprend pas ce qu'elle écrit
- mais l'IA ne produit que du contenu pas original
- mais l'IA ne fait que répéter ce qu'elle a appris

J'avoue que chacun de ces énoncés me font tiquer et répondre : "j'ai pas lu Luc Julia, mais ce que je lis ailleurs m'amène à un point de vue radicalement différent sur l'IA !"

À force, je suis allé acheter et lire les 3 livres de Luc Julia pour en avoir le cœur net.

---

### Les ouvrages de Luc Julia

- ***"L'Intelligence artificielle n'existe pas"***, First Editions (2019)
  > Accroche de couverture : "Le cocréateur de Siri déconstruit le mythe de l'IA !"

- ***"On va droit dans le mur ?"***, First Editions / le cherche midi (2022)
  > Sous-titre : "Pour sauver la planète, il faut un projet de société et une ambition de civilisation"

- ***"IA génératives pas créatives"***, le cherche midi (2025)
  > Sous-titre : l'intelligence artificielle n'existe (toujours) pas - par le cocréateur de Siri.

Je laisse de côté le deuxième ouvrage dont le sujet central est celui de l'action destructrice des sociétés humaines sur l'environnement.
L'IA y est évoquée très brièvement : extrêmement consommateur d'énergie, GPT-3 d'OpenAI est pris en exemple d'"outrance" et de "ridicule" (p.208-209).

Le premier ouvrage, paru en 2019 donc 3 ans avant l'irruption de ChatGPT, est un plaidoyer contre les effets d'hyperboles sur l'IA.
À commencer par le terme "IA", que Luc Julia critique comme incorrect, et qu'il redéfinit à sa manière.
Le "I" devrait vouloir dire **"information"** (comme dans le "I" de CIA : Central Intelligence Agency).
Et le "A" devrait vouloir dire **"augmentée"** plutôt que "artificielle", car l'IA est un amplificateur de l'humain, pas son concurrent synthétique.

Et pour cette raison, l'IA... n'existerait pas.

En 2019, ce type de discours critique et sceptique peut être intéressant.
Les capacités de l'IA sont impressionnantes (Google Translate, pour prendre un exemple) mais tellement loin d'approcher les capacités de l'intelligence humaine qu'un rappel de ses limites peut aider le grand public à y voir plus clair.

Mais qu'en est-il en 2025 avec son nouvel ouvrage, publié plus de 2 ans après la sortie de ChatGPT et de son adoption ultra rapide ? Et bien... **l'IA n'existe toujours pas pour Luc Julia.**

---

### Un florilège d'affirmations contre l'IA

J'ai lu le livre, puis je l'ai relu systématiquement pour relever les affirmations qui développent et soutiennent ce constat de non-existence de l'IA. Florilège :

- "ces IA [de génération d'images] ne créent rien" (p. 44)
- "ces IA racontent n'importe quoi et c'est normal. [...] c'est une sorte de moyenne de ce qu'elle trouve sur Internet" (p.52)
- L'IA manque de pertinence (p.53)
- "Avoir faux une fois sur 3, c'est grave ?" (pp.53)
- "incapacité à raisonner" (p. 54)
- "l'IA est tombée dans le panneau" (p. 62)
- "quand le grand public prendra conscience de l'impact énergétique des IA, il s'abstiendra d'en utiliser" (p. 85)
- "l'AGI [intelligence artificielle genérale] n'est pas pour demain (ni pour après-demain, d'ailleurs)" (p. 87)
- "L'IA ne pourra jamais innover" (p. 99).
- "L'IA créative est un oxymore" (p. 100)
- "réaliser des tâches complexes ≠ être intelligent" (p. 104)
- "l'IA ne raisonne pas, ne réfléchit pas" (p. 105)
- "l'IA n'est pas devenue plus intelligente, c'est même l'inverse" (p. 110)
- "Comme l'algorithme attend un certain type de réponse mais qu'il ne le trouve pas dans sa base de données, alors il fait du remplissage avec n'importe quoi" (p. 111)
- "il n'y a pas d'inexplicabilité quand on parle d'IA" (p. 122)
- "il n'arrivera jamais qu'une IA décide de se rebeller et d'attaquer l'homme de son plein gré" (p. 133)
- "il est plus sûr d'aller vérifier une information sur Google qu'au travers d'une IA générative" (p. 141)
- "Seuls 5% des emplois seront réellement menacés [par l'IA]. C'est assez peu quand on y pense." (p. 149)
- "il est de plus en plus évident que les LLM (grands modèles de langue) ne sont pas viables à long terme" (p. 180)
- "si on regarde sous le capot, on constate qu'elles [les IA] ne se sont pas améliorées du tout." (p. 182)
- "Ce qui doit arriver arrivera : le rêve de l'AGI [...] sera une nouvelle fois abandonné et les IA génériques disparaîtront progressivement" (p. 241)
- "Ces IA ne sont qu'une évolution mathématique parmi d'autres" (p. 250)

Je vois comme un *pattern*, pas vous ?

---

### Sources et usages : une base fragile

Sur quels usages et expériences personnelles et professionnelles de l'IA générative Luc Julia se base-t-il ? Quatre exemples sont partagés dans ce livre de 250 pages :

1.  "Prenons un exemple pour démontrer que ces IA ne créent rien. [...] Dans le prompt, je saisis 'Dessine-moi des vaches vertes sur la tour Eiffel'. [...] " (p.44)
2.  "Il y a un petit jeu que j'adore faire avec ces IA, c'est leur faire raconter n'importe quoi sur des sujets que je maîtrise. [...] je m'amuse souvent à générer ma biographie sur ChatGPT, Gemini ou autre." (p. 52).
3.  "Je me suis amusé à demander ce qu'est l'éthique à ChatGPT et voici sa réponse [...]" (p. 156)
4.  "Par exemple l'autre jour je me suis amusé à créer un deepfake de mon directeur actuel, Luca de Meo (PDG de Renault) [...] (p. 224)

Le secret professionnel interdit peut-être à l'auteur de partager des expériences plus poussées, mais ces 4 exemples suggèrent un usage très rudimentaire.

Mais alors sur quelles sources documentaires s'appuie l'ouvrage ?

Il s'agit de toucher le grand public, donc on aurait pu s'attendre à un mélange d'études scientifiques mesurant les performances de l'IA générative, et évaluant rigoureusement ses premiers impacts sur la société : le tout distillé et expliqué de façon didactique.
Au lieu de ça, l'ouvrage s'appuie sur 26 références qui sont pour la plupart des articles de presse en ligne.
Le drône qui se serait retourné contre son pilote, une déclaration de Sam Altman, Coca-Cola qui annonce une nouvelle recette conçue par l'IA...
On peut certes trouver ces articles et brèves très intéressants, mais ils ne remplissent pas la même fonction que des études publiées dans des revues scientifiques que l'on appelle "à comité de lecture", c'est-à-dire des recherches approfondies qui s'engagent à suivre une démarche méthodologique rigoureuse, vérifiée par des chercheurs avant publication.

---

### L'argument massue des "36% d'erreurs"

Il y a néanmoins un article scientifique mentionné (p. 53) qui est important, car il établit que l'IA se tromperait **36% du temps**.
Luc Julia commente : *"Si un collègue de travail dit 36% de bêtises, en temps normal, on ne le garde pas dans l'entreprise"* (pp. 53-54).

Plusieurs problèmes avec cet article et son interprétation :

-   **Il est difficile à trouver :** il n'est pas référencé dans le livre.
-   **Le test est limité :** l'étude ne porte que sur 148 exemples, non des "millions de faits avérés".
-   **Le test n'évalue pas la "véracité" :** il s'agit de tests logiques sur des paires de phrases, pas de vérification de faits.
-   **Le contexte est très spécifique :** l'étude mesure comment l'IA réagit à des phrases contenant des fautes intentionnelles. C'est dans ce contexte de phrases modifiées que le taux d'erreur de 36% est atteint.
-   **La version de l'IA est obsolète :** l'article teste GPT-3.5 de début 2023, une version bien moins puissante que GPT-4 (mars 2023) ou GPT-4o (mai 2024), disponibles bien avant la publication du livre en 2025.

Cet argument des "36% d'erreurs", basé sur une interprétation douteuse d'une étude limitée, est pourtant repris abondamment dans les interventions publiques de l'auteur.

---

### Un graphique qui pose question

Le seul graphique du livre présente une stagnation et une diminution du nombre de visites sur le site de ChatGPT.

![Graphique tronqué des visites de ChatGPT s'arrêtant en août 2023](https://place-hold.it/800x400?text=Graphique+visites+ChatGPT+jusqu'à+Août+2023)

Problème : le graphique s'arrête en **août 2023**. C'est ancien pour un livre publié en 2025. Voici le graphique complet :

![Graphique complet des visites de ChatGPT montrant une croissance continue après août 2023](https://place-hold.it/800x400?text=Graphique+complet+visites+ChatGPT+jusqu'en+2025)

L'image est bien différente. Après une stagnation estivale en 2023, les visites ont **doublé l'année suivante**. Présenter un graphique tronqué est intellectuellement malhonnête.

---

### Conclusion : vers la "Co-intelligence"

Ce qui voulait être un article bref est devenu un texte bien trop long. Plutôt que de contre-argumenter point par point, je préfère recommander une seule référence : ***'Co-intelligence : Vivre et travailler avec l'IA'***, la traduction française (2025) du livre d'Ethan Mollick paru en 2024.

Cet ouvrage est une merveille de nuances, de synthèse d'études, et d'expériences riches, avec un sens critique et une vision hors pair.

L'ironie ? Sa préface est écrite par... **Luc Julia !** :-)
